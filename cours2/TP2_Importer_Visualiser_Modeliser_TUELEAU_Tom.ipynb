{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# TP 2 — Démarrer un projet de zéro : importer, visualiser, modéliser\n\n**Auteur : TUELEAU Tom**  \n**Date : 5 septembre 2025**\n\n**Objectifs :**\n- Créer l’ossature d’un projet (`venv`, arborescence).\n- Importer un jeu de données (URL publique, fichier local, jeu intégré).\n- Explorer et **visualiser** les données.\n- Entraîner un **premier** modèle de machine learning (intro)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# (Optionnel) Créer une arborescence minimale pour le projet\n# Vous pouvez exécuter cette cellule une fois au début.\nimport os\nfor d in [\"data\", \"notebooks\", \"src\"]:\n    os.makedirs(d, exist_ok=True)\nprint(\"Dossiers prêts :\", os.listdir(\".\"))"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Dépendances (exécuter si besoin) :\n# %pip install pandas matplotlib scikit-learn\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.datasets import load_wine\n\n# Paramètres graphiques (taille par défaut)\nplt.rcParams[\"figure.figsize\"] = (6, 4)"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 1) Choisir et charger un dataset\n\n- `DATASET = \"penguins\"` (via URL publique ; alternative locale `data/penguins.csv`).\n- `DATASET = \"wine\"` (jeu intégré scikit‑learn, pas d’Internet requis)."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Choix du dataset : \"penguins\" ou \"wine\"\nDATASET = \"penguins\"  # <-- changez ici si vous voulez utiliser \"wine\"\n\ndf = None\ntarget_col = None\ntarget_names = None\n\nif DATASET == \"penguins\":\n    URL = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/penguins.csv\"\n    try:\n        df = pd.read_csv(URL)\n    except Exception as e:\n        print(\"Échec du chargement par URL, tentative locale 'data/penguins.csv'...\", e)\n        df = pd.read_csv(\"data/penguins.csv\")  # Assurez-vous d'avoir ce fichier si vous êtes hors-ligne\n    target_col = \"species\"\n    target_names = sorted(df[target_col].dropna().unique().tolist())\nelif DATASET == \"wine\":\n    wine = load_wine(as_frame=True)\n    df = wine.frame.copy()     # features + target (0,1,2)\n    target_col = \"target\"\n    target_names = list(wine.target_names)\nelse:\n    raise ValueError(\"DATASET doit être 'penguins' ou 'wine'.\")\n\nprint(\"Dataset :\", DATASET, \"| Forme :\", df.shape)\ndf.head()"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "## Inspection rapide\ndisplay(df.head())\nprint(\"\\n=== Info ===\")\ndf.info()\nprint(\"\\n=== Statistiques (numériques) ===\")\ndisplay(df.select_dtypes(include=\"number\").describe())\nprint(\"\\n=== Valeurs manquantes par colonne ===\")\ndisplay(df.isna().sum())"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "## 2) Préparation : sélection colonnes numériques + cible\n\n# Déterminer toutes les colonnes numériques\nall_num = df.select_dtypes(include=\"number\").columns.tolist()\n\n# Pour 'penguins', on retient des colonnes num. courantes si présentes\npenguins_default = [\"bill_length_mm\",\"bill_depth_mm\",\"flipper_length_mm\",\"body_mass_g\"]\nif DATASET == \"penguins\":\n    num_cols = [c for c in penguins_default if c in df.columns]\nelse:\n    # 'wine' : on peut prendre les 6 premières colonnes numériques pour simplifier les graphiques\n    num_cols = [c for c in all_num if c != target_col][:6]\n\n# Nettoyage minimal : garder lignes complètes sur les colonnes choisies + la cible\nkeep_cols = num_cols + [target_col]\ndf_clean = df[keep_cols].dropna().copy()\n\n# Cible catégorielle lisible\nif DATASET == \"penguins\":\n    df_clean[target_col] = df_clean[target_col].astype(\"category\")\n    class_labels = list(df_clean[target_col].cat.categories)\nelse:\n    # 'wine' : classes 0,1,2 -> noms explicites si dispo\n    df_clean[target_col] = df_clean[target_col].astype(\"category\")\n    class_labels = target_names  # ['class_0','class_1','class_2'] dans wine.target_names\n\nX = df_clean[num_cols]\ny = df_clean[target_col].astype(\"category\")\n\nprint(\"Variables numériques utilisées :\", num_cols)\nprint(\"Forme X/y :\", X.shape, y.shape)\nprint(\"Classes :\", list(y.cat.categories))"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "## 3) Visualisations — distributions (histogrammes)\nfor col in num_cols:\n    plt.figure()\n    X[col].hist(bins=20)\n    plt.title(f\"Distribution de {col}\")\n    plt.xlabel(col); plt.ylabel(\"Fréquence\")\n    plt.tight_layout(); plt.show()"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "## 3) Visualisations — variabilité par classe (boîtes à moustaches)\nfor col in num_cols:\n    plt.figure()\n    data_by_class = [X.loc[y==cl, col] for cl in y.cat.categories]\n    plt.boxplot(data_by_class, labels=list(y.cat.categories))\n    plt.title(f\"{col} par classe\")\n    plt.xlabel(\"Classe\"); plt.ylabel(col)\n    plt.tight_layout(); plt.show()"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "## 3) Visualisations — relations entre variables (nuages de points)\n# Construire jusqu'à deux paires (a,b) pour ne pas surcharger\npairs = []\nfor i in range(0, min(len(num_cols), 4), 2):\n    if i+1 < len(num_cols):\n        pairs.append((num_cols[i], num_cols[i+1]))\n\ncodes = y.cat.codes  # 0..K-1 (utilisé pour colorer sans choisir de couleurs spécifiques)\nfor a,b in pairs:\n    plt.figure()\n    plt.scatter(X[a], X[b], c=codes)\n    plt.title(f\"{a} vs {b} (couleur = classe)\")\n    plt.xlabel(a); plt.ylabel(b)\n    cbar = plt.colorbar(ticks=sorted(codes.unique()))\n    try:\n        cbar.ax.set_yticklabels(list(y.cat.categories))\n    except Exception:\n        pass\n    plt.tight_layout(); plt.show()"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "## 3) Visualisations — corrélations (matrice)\ncorr = X.corr(numeric_only=True)\nfig, ax = plt.subplots()\ncax = ax.matshow(corr.values)\nfig.colorbar(cax)\nax.set_xticks(range(len(corr.columns)))\nax.set_yticks(range(len(corr.columns)))\nax.set_xticklabels(corr.columns, rotation=45, ha=\"left\")\nax.set_yticklabels(corr.columns)\nplt.title(\"Corrélations entre variables\")\nplt.tight_layout(); plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 4) Introduction au machine learning (classification)\nWorkflow minimal : séparation train/test → standardisation → apprentissage → évaluation."
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Découpage + pipeline standardisation + régression logistique\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\npipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))\npipe.fit(X_train, y_train)\npred = pipe.predict(X_test)\n\nprint(\"Accuracy :\", accuracy_score(y_test, pred))\nprint(classification_report(y_test, pred))"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Matrice de confusion\ncm = confusion_matrix(y_test, pred, labels=list(y.cat.categories))\nfig, ax = plt.subplots()\nim = ax.imshow(cm)\nax.set_xticks(range(len(y.cat.categories))); ax.set_yticks(range(len(y.cat.categories)))\nax.set_xticklabels(y.cat.categories, rotation=45, ha=\"right\")\nax.set_yticklabels(y.cat.categories)\nplt.title(\"Matrice de confusion\")\nfor i in range(cm.shape[0]):\n    for j in range(cm.shape[1]):\n        ax.text(j, i, cm[i, j], ha=\"center\", va=\"center\")\nplt.tight_layout(); plt.show()"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## 5) À rendre / Questions guidées\n1. **Import** : testez `penguins` puis `wine`. Avantages/inconvénients (qualité des colonnes, propreté, taille) ?  \n2. **Nettoyage** : listez les colonnes avec NA et justifiez votre stratégie (suppression vs imputation).  \n3. **Visualisation** : pour chaque graphique, écrivez une phrase d’interprétation (tendance, dispersion, séparabilité des classes).  \n4. **Modèle** : remplacez la régression logistique par `KNeighborsClassifier` puis `DecisionTreeClassifier`. Comparez l’accuracy.  \n5. **Reproductibilité** : exportez l’environnement (`pip freeze > requirements.txt`) et donnez les étapes pour relancer le projet sur une autre machine."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "authors": [
      {
        "name": "TUELEAU Tom"
      }
    ],
    "created": "2025-09-05T13:25:42.527273Z"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}